{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "gym.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/btlgs2000/mini_degree_Reinforcement_Learning/blob/master/gym.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNFNrd_Ft2Me"
      },
      "source": [
        "# Gym\n",
        "\n",
        "## Link utili:\n",
        "\n",
        "* Sito OpenAI: https://openai.com/\n",
        "\n",
        "* GitHub OpenAI: https://github.com/openai\n",
        "\n",
        "* Url Gym: https://gym.openai.com/\n",
        "\n",
        "* GitHub Gym: https://github.com/openai/gym\n",
        "\n",
        "* Wiki di Gym: https://github.com/openai/gym/wiki\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjsU4503t2Mf"
      },
      "source": [
        "## Giochiamo a Space Invaders!\n",
        "\n",
        "![img](https://github.com/btlgs2000/mini_degree_Reinforcement_Learning/blob/master/img/space_invaders.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHBtrpWpuD0a"
      },
      "source": [
        "!pip install gym pyvirtualdisplay\n",
        "!apt-get install -y xvfb python-opengl ffmpeg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXT4K29MuH7m"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install cmake\n",
        "!pip install --upgrade setuptools\n",
        "!pip install ez_setup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5W-e7bZt2Mj"
      },
      "source": [
        "import gym\n",
        "import time\n",
        "import numpy as np\n",
        "from gym.wrappers import Monitor\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "from IPython import display as ipythondisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX87n7Znt2Mv"
      },
      "source": [
        "\n",
        "Creiamo una funzione che **genera episodi** dell'ambiente passato come parametro."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCRLbiDgvVog"
      },
      "source": [
        "def show_video(filename):\n",
        "    video = open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "            </video>'''.format(encoded.decode('ascii'))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQlRECist2My"
      },
      "source": [
        "def generate_episodes(env, sleep_seconds=0, get_action=None, max_steps=float('inf'), num_episodes=1,\n",
        "                   folder, verbosity=0):\n",
        "    '''\n",
        "    Genera episodi di un ambiente gym\n",
        "    \n",
        "    Parametri\n",
        "    ---------\n",
        "    env : un ambiente gym\n",
        "    sleep_seconds : tempo di attesa in secondi tra due frame consecutivi\n",
        "    get_action : una funzione che prende un'osservazione e restituisce un'azione.\n",
        "                 Se None le azioni sono scelte casualmente\n",
        "    max_steps : numero massimo di step dell'episodio. La funziona ritorna quando\n",
        "                l'episodio è terminato o quando si è raggiunmto il numero di step\n",
        "                massimo.\n",
        "    num_episodes : numero di episodi da generare\n",
        "    folder: cartella in cui vengono salvati i video con numerazione progressiva\n",
        "    verbosity : 0, 1, 2. Quante informazioni stampare a video\n",
        "    \n",
        "    Ritorno\n",
        "    -------\n",
        "    Una lista con le lunghezze degli episodi generati\n",
        "    '''\n",
        "\n",
        "    return lenghts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8zrWVKMt2M6"
      },
      "source": [
        "Facciamo una partita a **Space Invaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1b_Cdpkxeiw"
      },
      "source": [
        "env = gym.make('SpaceInvaders-v0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzHr14wBt2M7"
      },
      "source": [
        "env = gym.make('SpaceInvaders-v0')\n",
        "generate_episodes(env, sleep_seconds=0.01, verbosity=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qslISWXIt2NC"
      },
      "source": [
        "Alcune osservazioni:\n",
        "* Nei giochi **Atari** `info` (l'ultimo elemento della tupla ritornata da `step`) comunica quante **vite** sono rimaste.\n",
        "<br><br>\n",
        "* observation è un **array numpy** di dimensioni (210, 160, 3) che rappresenta un frame di gioco. Le prime due dimensioni rappresentano rispettivamente la largezza e l'altezza del frame, la terza i canali RGB.\n",
        "<br><br>\n",
        "* I **missili** sparati dalle astronavi **non sono visibili** in tutti i frame a causa delle **limitazioni hardware** dell'Atari 2600. A riguardo è possibile leggere [questo interssante articolo](https://www.wired.com/2009/03/racing-the-beam)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-0zM4CFt2NE"
      },
      "source": [
        "## La classe Env\n",
        "La classe più importante nell'architettura di Gym è `gym.Env`. È una classe astratta da cui ereditano tutti gli ambienti definiti nel package `gym.envs`.\n",
        "<br>\n",
        "I metodi principali della classe `Env` sono:\n",
        "* `step`: esegue un **passo** della simulazione prendendo in input un'azione. Ritorna la tupla (observation, reward, done, info) in cui **observation** è lo stato dell'ambiente dopo l'esecuzione dell'azione, **reward** è la ricompensa ricevuta, **done** vale True se l'episodio è terminato, **info** contiene informazioni ausiliarie.\n",
        "* `reset`: **inizializza** l'ambiente ritornandone il primo stato. Va chiamata **all'inizio** di ogni nuovo episodio.\n",
        "* `render`: ritorna una **rappresentazione grafica** dello stato corrente dell'ambiente. Ha le seguenti opzioni:\n",
        " * `human`: visualizza lo stato all'interno di una finestra.\n",
        " * `rgb_array`: ritorna un **array numpy** di dimensioni (larhezza, altezza, 3) che rappresenta un'immagine dello stato corrente dell'ambiente.\n",
        " * `ansi`: ritorna una **stringa** che rappresenta una visualizzazione adatta ad un **terminale** dello stato corrente.\n",
        "* `close`: esegue operazioni di **pulizia** finale.\n",
        "* `seed`: imposta il seme del generatore di **numeri causali** dell'ambiente.\n",
        "\n",
        "Il modo più semplice per **creare** un ambiente è utilizzare la funzione `gym.make` passandogli l'id dell'ambiente.\n",
        "<br>\n",
        "Si può creare un **nuovo ambiente** creando una classe che **eredita** da `Env` e ridefinendo i suoi metodi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3FIOsw6t2NG"
      },
      "source": [
        "## La classe Space\n",
        "\n",
        "Ogni ambiente ha un `action_space` (con le possibili azioni) e un `observation_space` (con i possibili stati) come attributi.\n",
        "Tutti gli **spazi** sono sottoclassi di gym.Space e sono definiti nel package `gym.spaces`.\n",
        "\n",
        "I possibili spazi sono:\n",
        "* `Discrete(n)`: i suoi elementi sono i numeri interi da $0$ a $n-1$.\n",
        "* `Box`: rappresenta uno spazio continuo. Ad esempio lo spazio degli stati dei giochi Atari è di tipo Box(210, 160, 3).\n",
        "* `Multibinary`: tupla di valori binari (0,1).\n",
        "* `Multidiscrete`: Tupla di variabili discrete.\n",
        "* `Tuple`: prodotto cartesiano di spazi.\n",
        "\n",
        "I metodi principali della classe `Space` sono\n",
        "* `contains`: restituisce `True` se gli viene passato un **elemento dello spazio** come parametro.\n",
        "* `sample`: ritorna un elemento **casuale** dello spazio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIn78Bs3t2NI"
      },
      "source": [
        "Analizziamo lo spazio delle azioni e lo spazio degli stati di **Space Invaders**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWZgWIAxt2NI"
      },
      "source": [
        "from gym.envs.atari.atari_env import ACTION_MEANING\n",
        "env = gym.make('SpaceInvaders-v0')\n",
        "print(f\"action space = {env.action_space}\")\n",
        "print(f\"observation space = {env.observation_space}\")\n",
        "print(f\"observation space shape = {env.observation_space.shape}\")\n",
        "# azioni possibili e loro descrizione\n",
        "print({k : v for k, v in ACTION_MEANING.items() if k in env.action_space})\n",
        "# gli spazi continui (di tipo Box) ammettono un massimo e un minimo per ogni elemento\n",
        "print(f\"observation space lower limits = {env.observation_space.low}\")\n",
        "print(f\"observation space upper limits = {env.observation_space.high}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzg5pbCht2NO"
      },
      "source": [
        "### Discrete\n",
        "È composto dai **numeri interi** da $0$ a $n$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80_wKARxt2NP"
      },
      "source": [
        "# lo spazio dei numeri interi da 0 a 9\n",
        "discrete = gym.spaces.Discrete(10)\n",
        "print(f\"spazio = {discrete}\")\n",
        "print(f\"n = {discrete.n}\")\n",
        "print(f\"sample = {discrete.sample()}\")\n",
        "print(f\"contiene 10 è {discrete.contains(10)}\")\n",
        "print(f\"contiene 9 è {discrete.contains(9)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5olsNlMt2NX"
      },
      "source": [
        "### Box\n",
        "È uno spazio **continuo**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh-fYfUMt2NZ"
      },
      "source": [
        "# spazio degli array numpy 2 x 3 in cui per ogni elemento vengono\n",
        "# specificati i valori minimo e massimo\n",
        "low = np.array([[-1.,-2.,-3.],[-2.,0.,-4.]])\n",
        "hi = np.array([[3.,4.,7.],[1.,10.,4.]])\n",
        "box = gym.spaces.Box(low, hi)\n",
        "print(f\"spazio = {box}\")\n",
        "print(f\"sample = {box.sample()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z54e2Z4et2Ne"
      },
      "source": [
        "### Multibinary\n",
        "\n",
        "I suoi elementi sono tuple di valori **binari**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsBjIB3Wt2Nf"
      },
      "source": [
        "# spazio delle tuple binarie composte da 5 elementi\n",
        "multi_binary = gym.spaces.MultiBinary(5)\n",
        "multi_binary.sample()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBBk3gDrt2Nm"
      },
      "source": [
        "### Multidiscrete\n",
        "\n",
        "* I suoi elementi sono **tuple di interi**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHam0ljht2No"
      },
      "source": [
        "# terne di interi in cui il primo elemento va da 0 a 6, iil secondo da 0 a 8, il terzo da 0 a 2\n",
        "multi_discrete = gym.spaces.MultiDiscrete([7, 9, 3])\n",
        "multi_discrete.sample()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dum02PD1t2Nu"
      },
      "source": [
        "### Tupla\n",
        "\n",
        "E' il **prodotto cartesiano** di spazi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6f_H4aqt2Nw"
      },
      "source": [
        "# coppie in cui il primo elemento è di tipo MultiBinary e il secondo di tipo MultiDiscrete\n",
        "tuple_ = gym.spaces.Tuple((gym.spaces.MultiBinary(5), gym.spaces.MultiDiscrete([7, 9, 3])))\n",
        "print(f\"spazio = {tuple_}\")\n",
        "tuple_.sample()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aeRYh-Bt2N1"
      },
      "source": [
        "## Ambienti disponibili"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buEstGxWt2N2"
      },
      "source": [
        "Sono registrati nel file `__init__.py` del package `gym/envs`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrYQftAct2N3"
      },
      "source": [
        "envs = gym.envs.registry.env_specs\n",
        "print(envs.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G84151eSt2N-"
      },
      "source": [
        "### Algorithmic\n",
        "\n",
        "L'agente deve programmare delle **macchine di Turing** ad eseguire semplici compiti, come **copiare una stringa**. Ogni macchina ha un nastro di input e uno di output, che possono essere uni o bi-dimensionali. Ad ogni istante l'agente deve deve:\n",
        "* **spostare la testina** del nastro di input in una delle due (o quattro nel caso bidimensionale) direzioni possibili\n",
        "* decidere se vuole **scrivere o meno** sul nastro di **output**\n",
        "* in caso positivo, **selezionare il carattere**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KegUFAiat2N_"
      },
      "source": [
        "generate_episodes(gym.make('Copy-v0'), sleep_seconds=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_uY6W8Dt2OD"
      },
      "source": [
        "## Atari\n",
        "\n",
        "Un **emulatore** dell' [Atari 2600](https://it.wikipedia.org/wiki/Atari_2600) con diversi giochi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H81b3XFZt2OF"
      },
      "source": [
        "generate_episodes(gym.make('SpaceInvaders-v0'), sleep_seconds=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X62BlGYKt2OL"
      },
      "source": [
        "## Box2D\n",
        "\n",
        "Ambienti che utilizzano la libreria di **fisica bidimensionale** [Box2D](https://box2d.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WraDSaXUt2OM"
      },
      "source": [
        "generate_episodes(gym.make('LunarLander-v2'), sleep_seconds=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb0VoSGVt2OQ"
      },
      "source": [
        "## Classic control\n",
        "\n",
        "**Sistemi fisici** estremamente **semplici** come il pendolo, il pendolo doppio e il pendolo inverso (**Cart-Pole**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcyPtBaAt2OR"
      },
      "source": [
        "generate_episodes(gym.make('CartPole-v0'), sleep_seconds=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW_PwoIjt2OX"
      },
      "source": [
        "## Toy text\n",
        "\n",
        "Semplici ambienti con visualizzazione **testuale**.\n",
        "<br>\n",
        "Nel **Frozen Lake** l'agente deve raggiungere la casella G (Goal) evitando le caselle H (Hole)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ8SJ9Let2OY"
      },
      "source": [
        "generate_episodes(gym.make('FrozenLake8x8-v0'), sleep_seconds=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLzsyuWDt2Oc"
      },
      "source": [
        "## I wrappers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z2LRP1gt2Oe"
      },
      "source": [
        "Un ambiente può essere creato invocando direttamente il **costruttore** della sua classe, oltre che tramite la funzione `gym.make`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvq1cWWnt2Of"
      },
      "source": [
        "from gym.envs.box2d.bipedal_walker import BipedalWalker\n",
        "env = BipedalWalker()\n",
        "generate_episodes(env, sleep_seconds=0.1, max_steps=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67KNmnBQt2Ok"
      },
      "source": [
        "Il comportamento di un ambiente può essere modificato, o nuove funzionalità possono esseregli aggiunte, utilizzando un oggetto **wrapper** (`gym.core.Wrapper`).\n",
        "<br><br>\n",
        "Possiamo monitorare un addestramento utilizzando il wrapper `Monitor` che salva su disco le **statistiche** e i **video** degli episodi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3oYnFPVt2Ol"
      },
      "source": [
        "from gym.wrappers.monitor import Monitor\n",
        "\n",
        "# salva i file nella sottocartella tmp della cartella corrente\n",
        "env = Monitor(gym.make(\"CartPole-v0\"), directory=\"./tmp\", force=True)\n",
        "generate_episodes(env, sleep_seconds=0, num_episodes=5, verbosity=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQVXD8aCt2Oq"
      },
      "source": [
        "Possiamo impostare un numero di step dopo i quali **interrompere l'episodio** anche se non è terminato, utilizzando `TimeLimit`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NOMsLt-t2Or"
      },
      "source": [
        "from gym.wrappers.time_limit import TimeLimit\n",
        "\n",
        "env = TimeLimit(BipedalWalker(), max_episode_steps=10)\n",
        "generate_episodes(env, sleep_seconds=0.1, verbosity=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5WIwroHt2Ov"
      },
      "source": [
        "Possiamo limitare il **range dei reward** ad un determinato intervallo tramite `ClipReward`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4o36Sxat2Ow"
      },
      "source": [
        "from gym.wrappers.clip_reward import ClipReward\n",
        "\n",
        "# limita a 0.5 il massimo reward\n",
        "rewards = []\n",
        "env = ClipReward(gym.make(\"CartPole-v0\"), min_r=0, max_r=0.5)\n",
        "env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    env.render()\n",
        "    observation, reward, done, info = env.step(env.action_space.sample())\n",
        "    rewards.append(reward)\n",
        "    time.sleep(0.1)\n",
        "env.close()\n",
        "# nel Cart Pole l'agente ottiene un reward di 1 ad ogni passo.\n",
        "# Dopo il clipping i reward valgono tutti 0.5\n",
        "print(rewards)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd6FUYYkt2O0"
      },
      "source": [
        "Ci sono altri wrapper oltre a quelli appena visti (nel package `gym.wrappers`) e naturalmente è possibile crearne di nuovi.\n",
        "<br>\n",
        "È inoltre possibile **comporre** più wrapper.\n",
        "<br>\n",
        "Possiamo ad esempio imporre **contemporaneamente** un limite alla **lunghezza** degli episodi e al **range** dei reward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX9zyLQFt2O1"
      },
      "source": [
        "env = TimeLimit(ClipReward(BipedalWalker(), min_r=0, max_r=0.5), max_episode_steps=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTiLBpoMt2O6"
      },
      "source": [
        "Ogni wrapper espone l'ambiente (o il wrapper) **precedente** con l'attributo `env` e l'ambiente **originario** con l'attributo `unwrapped`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83U5-Y91t2O7"
      },
      "source": [
        "print(env)\n",
        "print(env.env)\n",
        "print(env.unwrapped)\n",
        "# come env.unwrapped\n",
        "print(env.env.env)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4aAFnhrt2PA"
      },
      "source": [
        "## Gli ambienti registrati"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kASePhwmt2PA"
      },
      "source": [
        "Possiamo vedere quali sono gli ambienti registrati consultando il **registro globale**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_1mLoPct2PB"
      },
      "source": [
        "sorted([spec for spec in gym.envs.registry.env_specs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbQLsYFSt2PJ"
      },
      "source": [
        "Un ambiente registrato viene creato tramite la funzione `gym.make`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3432sl2t2PL"
      },
      "source": [
        "cartpole_v0 = gym.make(\"CartPole-v0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rscm4-VZt2PO"
      },
      "source": [
        "Gli ambienti registrati sono gli ambienti **ufficiali** su cui possiamo testare i nostri algortimi e **confrontarli** con quelli degli altri.  [Questa pagina](https://github.com/openai/gym/wiki/Leaderboard) ospita la **classifica** dei migliori algoritmi (in termini di numero di episodi necessari a superare la sfida). Studiarli è un otimo modo per accrescere le proprie competenze di Reinforcement Learning.\n",
        "<br><br>\n",
        "Ad ogni ambiente registrato corrispondono delle **specifiche** (un ogetto della classe `EnvSpec`) accessibili tramite l'attrivuto `spec`.\n",
        "<br><br>\n",
        "Il **CartPole** è presente con le versioni 0 e 1. Nella prima ogni episodio ha una durata massimo di 200 passi (ottenuta con il wrapper TimeLimit). Il compito è considerato **risolto** quando gli ultimi 100 episodi hanno una durata media di almeno 195 passi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2b9Ke_Clt2PP"
      },
      "source": [
        "print(\"soglia = {}, massimo numero di passi per episodio = {}\".format(cartpole_v0.spec.reward_threshold, \n",
        "                                                                      cartpole_v0.spec.max_episode_steps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUjSgSXSt2PW"
      },
      "source": [
        "## Un algoritmo per il pendolo inverso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HpVF5mUt2PW"
      },
      "source": [
        "In questa sezione ti proponiamo una piccola **sfida**: ideare un algoritmo che risolva il problema del **Cart Pole**.\n",
        "<br>\n",
        "Il Cart Pole è un semplice sistema fisico costituito da un'**asta** imperniata ad un **carrello**, libera di ruotare. È completamente descritto da **quattro parametri**: la posizione del carrello, la sua velocità, l'angolo dell'asta, la sua velocità angolare. L'obiettivo è di tenere **l'asta in equilibrio** senza allontanare troopo il carrello dalla posizione centrale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BskKIJzmt2PX"
      },
      "source": [
        "Un'occhiata alla **documentazione** della classe `CartPoleEnv` potrebbe esserti utile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yev8RRAVt2PZ"
      },
      "source": [
        "print(gym.envs.classic_control.CartPoleEnv.__doc__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaTIj4yWt2Pc"
      },
      "source": [
        "La funzione `get_action` prende in input uno **stato** e restituisce un'**azione** (per ora scelta a caso). Ti chiediamo di implementarla in modo tale da raggiungere l'obiettivo di una durata media di almeno **195 passi** sui 200 massimi, clacolata su 100 episodi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIotmEm2t2Pd"
      },
      "source": [
        "def get_action(observation):\n",
        "    import random\n",
        "    return random.choice([0, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ideOV4yTt2Pf"
      },
      "source": [
        "env = gym.make(\"CartPole-v0\")\n",
        "lenghts = generate_episodes(env, get_action=get_action, num_episodes=100)\n",
        "\n",
        "if np.mean(lenghts) >= 195:\n",
        "    print(\"Bravo, hai superato la prova!\")\n",
        "else:\n",
        "    print(f\"La lunghezza media dei 100 episodi è stata di {np.mean(lenghts)}. Devi migliorare!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}